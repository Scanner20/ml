{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO7+OGT+90wcvMjdZmTek3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scanner20/ml/blob/main/TF_ML_Grupo3_RF_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgK-_VGSF4Qf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "path = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/marketing_campaign.csv\"\n",
        "data = pd.read_csv(path, sep=';')\n",
        "\n",
        "\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "FaPHlFoxxd8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    r2_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Data Loading\n",
        "path = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/marketing_campaign.csv\"\n",
        "data = pd.read_csv(path, sep=';')\n",
        "\n",
        "# 2. Initial Data Exploration\n",
        "def explore_data(df):\n",
        "    print(\"Dataset Information:\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    print(\"\\nDescriptive Statistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "# 3. Data Preprocessing\n",
        "def preprocess_data(df):\n",
        "    # Create a copy of the dataframe\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Handle missing values\n",
        "    # Replace income NaNs with median\n",
        "    df_processed['Income'] = df_processed['Income'].fillna(df_processed['Income'].median())\n",
        "\n",
        "    # Calculate age\n",
        "    df_processed['Age'] = 2024 - df_processed['Year_Birth']\n",
        "\n",
        "    # Categorize age groups\n",
        "    def categorize_age(age):\n",
        "        if age < 30:\n",
        "            return 'Young'\n",
        "        elif 30 <= age < 45:\n",
        "            return 'Middle'\n",
        "        else:\n",
        "            return 'Senior'\n",
        "\n",
        "    df_processed['AgeGroup'] = df_processed['Age'].apply(categorize_age)\n",
        "\n",
        "    # Select features for modeling\n",
        "    features = [\n",
        "        'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
        "        'NumDealsPurchases', 'NumWebPurchases',\n",
        "        'NumCatalogPurchases', 'NumStorePurchases',\n",
        "        'NumWebVisitsMonth', 'Education', 'Marital_Status',\n",
        "        'AgeGroup'\n",
        "    ]\n",
        "\n",
        "    # Prepare X and y\n",
        "    X = df_processed[features]\n",
        "    y = df_processed['MntWines']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# 4. Model Preparation and Training\n",
        "def prepare_and_train_model(X, y):\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Preprocessing for numerical and categorical columns\n",
        "    numeric_features = [\n",
        "        'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
        "        'NumDealsPurchases', 'NumWebPurchases',\n",
        "        'NumCatalogPurchases', 'NumStorePurchases',\n",
        "        'NumWebVisitsMonth'\n",
        "    ]\n",
        "\n",
        "    categorical_features = [\n",
        "        'Education', 'Marital_Status', 'AgeGroup'\n",
        "    ]\n",
        "\n",
        "    # Create preprocessor\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            # Numeric columns: impute missing values and scale\n",
        "            ('num', Pipeline([\n",
        "                ('imputer', SimpleImputer(strategy='median')),\n",
        "                ('scaler', StandardScaler())\n",
        "            ]), numeric_features),\n",
        "\n",
        "            # Categorical columns: one-hot encoding\n",
        "            ('cat', Pipeline([\n",
        "                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "            ]), categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Create a pipeline with preprocessor and random forest\n",
        "    rf_pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = rf_pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\nModel Evaluation:\")\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"Mean Absolute Error: {mae}\")\n",
        "    print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "    # Feature importance\n",
        "    feature_names = (\n",
        "        numeric_features +\n",
        "        list(rf_pipeline.named_steps['preprocessor']\n",
        "             .named_transformers_['cat']\n",
        "             .named_steps['onehot']\n",
        "             .get_feature_names_out(categorical_features))\n",
        "    )\n",
        "\n",
        "    feature_importance = rf_pipeline.named_steps['regressor'].feature_importances_\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    feature_imp = pd.Series(feature_importance, index=feature_names).sort_values(ascending=False)\n",
        "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "    plt.title('Feature Importance in Predicting Wine Purchases')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return rf_pipeline\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == '__main__':\n",
        "    # Explore the data\n",
        "    explore_data(data)\n",
        "\n",
        "    # Preprocess the data\n",
        "    X, y = preprocess_data(data)\n",
        "\n",
        "    # Eliminar filas con NaNs\n",
        "    X = X.dropna()\n",
        "    y = y[X.index]\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    model = prepare_and_train_model(X, y)"
      ],
      "metadata": {
        "id": "FhRvSAB860k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "zU2geQgjBbIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPARATIVA DE MODELOS"
      ],
      "metadata": {
        "id": "P2Fl82dfknoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# A. Ingeniería de características mejorada\n",
        "def advanced_feature_engineering(df):\n",
        "    # Copia del dataframe original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Características de interacción\n",
        "    df_processed['Income_per_Family_Member'] = df_processed['Income'] / (df_processed['Kidhome'] + df_processed['Teenhome'] + 1)\n",
        "\n",
        "    # Características de compras\n",
        "    df_processed['Total_Purchases'] = (\n",
        "        df_processed['NumDealsPurchases'] +\n",
        "        df_processed['NumWebPurchases'] +\n",
        "        df_processed['NumCatalogPurchases'] +\n",
        "        df_processed['NumStorePurchases']\n",
        "    )\n",
        "\n",
        "    # Características de tiempo\n",
        "    df_processed['Customer_Age'] = 2024 - df_processed['Year_Birth']\n",
        "    df_processed['Days_Since_First_Purchase'] = pd.to_datetime('2024-01-01') - pd.to_datetime(df_processed['Dt_Customer'])\n",
        "    df_processed['Days_Since_First_Purchase'] = df_processed['Days_Since_First_Purchase'].dt.days\n",
        "\n",
        "    # Categorización de ingresos\n",
        "    def categorize_income(income):\n",
        "        if pd.isna(income):\n",
        "            return 'Unknown'\n",
        "        elif income < df_processed['Income'].quantile(0.25):\n",
        "            return 'Low'\n",
        "        elif income < df_processed['Income'].quantile(0.75):\n",
        "            return 'Medium'\n",
        "        else:\n",
        "            return 'High'\n",
        "\n",
        "    df_processed['Income_Category'] = df_processed['Income'].apply(categorize_income)\n",
        "\n",
        "    # Características de productos\n",
        "    product_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "    df_processed['Total_Product_Spending'] = df_processed[product_columns].sum(axis=1)\n",
        "    df_processed['Spending_Diversity'] = (df_processed[product_columns] > 0).sum(axis=1)\n",
        "\n",
        "    # Selección de características\n",
        "    features = [\n",
        "        'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
        "        'NumDealsPurchases', 'NumWebPurchases',\n",
        "        'NumCatalogPurchases', 'NumStorePurchases',\n",
        "        'NumWebVisitsMonth', 'Education', 'Marital_Status',\n",
        "        'Income_per_Family_Member', 'Total_Purchases',\n",
        "        'Customer_Age', 'Days_Since_First_Purchase',\n",
        "        'Income_Category', 'Total_Product_Spending',\n",
        "        'Spending_Diversity'\n",
        "    ]\n",
        "\n",
        "    # Eliminar filas con valores NaN en características clave\n",
        "    df_processed_cleaned = df_processed.dropna(subset=features + ['MntWines'])\n",
        "\n",
        "    X = df_processed_cleaned[features]\n",
        "    y = df_processed_cleaned['MntWines']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# B. Simulación de recopilación de más datos (técnica de bootstrapping)\n",
        "def bootstrap_data(X, y, n_iterations=5):\n",
        "    bootstrapped_datasets = []\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # Muestreo con reemplazo\n",
        "        indices = np.random.randint(0, len(X), len(X))\n",
        "        X_bootstrap = X.iloc[indices]\n",
        "        y_bootstrap = y.iloc[indices]\n",
        "\n",
        "        bootstrapped_datasets.append((X_bootstrap, y_bootstrap))\n",
        "\n",
        "    return bootstrapped_datasets\n",
        "\n",
        "# C. Comparación de múltiples algoritmos y métodos de ensemble\n",
        "def compare_models(X, y):\n",
        "    # Preparación de datos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Definición de modelos a comparar\n",
        "    models = {\n",
        "        'Random Forest': RandomForestRegressor(random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "        'HistGradient Boosting': HistGradientBoostingRegressor(random_state=42),\n",
        "        'Linear Regression': LinearRegression()\n",
        "    }\n",
        "\n",
        "    # Resultados de los modelos\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Preprocesamiento específico para cada modelo\n",
        "        if name in ['Random Forest', 'Gradient Boosting', 'HistGradient Boosting']:\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='median')),\n",
        "                        ('scaler', StandardScaler())\n",
        "                    ]), X.select_dtypes(include=['int64', 'float64']).columns),\n",
        "                    ('cat', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "                    ]), X.select_dtypes(include=['object']).columns)\n",
        "                ])\n",
        "\n",
        "            pipeline = Pipeline([\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "\n",
        "        else:\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='median')),\n",
        "                        ('scaler', StandardScaler())\n",
        "                    ]), X.select_dtypes(include=['int64', 'float64']).columns),\n",
        "                    ('cat', Pipeline([\n",
        "                        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "                    ]), X.select_dtypes(include=['object']).columns)\n",
        "                ])\n",
        "\n",
        "            pipeline = Pipeline([\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "\n",
        "        # Entrenamiento y evaluación\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        results[name] = {\n",
        "            'MSE': mean_squared_error(y_test, y_pred),\n",
        "            'MAE': mean_absolute_error(y_test, y_pred),\n",
        "            'R2': r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "    # Visualización de resultados\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    metrics = ['MSE', 'MAE', 'R2']\n",
        "    for metric in metrics:\n",
        "        values = [results[model][metric] for model in results]\n",
        "        plt.bar([f\"{model}\\n{metric}\" for model in results], values)\n",
        "\n",
        "    plt.title('Comparación de Modelos')\n",
        "    plt.ylabel('Valor de Métrica')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecución principal\n",
        "if __name__ == '__main__':\n",
        "    # Carga de datos\n",
        "    path = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/marketing_campaign.csv\"\n",
        "    data = pd.read_csv(path, sep=';')\n",
        "\n",
        "    # A. Ingeniería de características\n",
        "    X, y = advanced_feature_engineering(data)\n",
        "\n",
        "    # B. Bootstrapping de datos\n",
        "    bootstrapped_datasets = bootstrap_data(X, y)\n",
        "\n",
        "    # Resultados de bootstrapping\n",
        "    print(\"Número de conjuntos de datos bootstrap:\", len(bootstrapped_datasets))\n",
        "\n",
        "    # C. Comparación de modelos\n",
        "    model_comparison_results = compare_models(X, y)\n",
        "\n",
        "    # Impresión de resultados de comparación\n",
        "    for model, metrics in model_comparison_results.items():\n",
        "        print(f\"\\nResultados para {model}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "id": "M7v5mH1peCg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def advanced_feature_engineering(df):\n",
        "    # Same as previous implementation\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Características de interacción\n",
        "    df_processed['Income_per_Family_Member'] = df_processed['Income'] / (df_processed['Kidhome'] + df_processed['Teenhome'] + 1)\n",
        "\n",
        "    # Características de compras\n",
        "    df_processed['Total_Purchases'] = (\n",
        "        df_processed['NumDealsPurchases'] +\n",
        "        df_processed['NumWebPurchases'] +\n",
        "        df_processed['NumCatalogPurchases'] +\n",
        "        df_processed['NumStorePurchases']\n",
        "    )\n",
        "\n",
        "    # Características de tiempo\n",
        "    df_processed['Customer_Age'] = 2024 - df_processed['Year_Birth']\n",
        "    df_processed['Days_Since_First_Purchase'] = pd.to_datetime('2024-01-01') - pd.to_datetime(df_processed['Dt_Customer'])\n",
        "    df_processed['Days_Since_First_Purchase'] = df_processed['Days_Since_First_Purchase'].dt.days\n",
        "\n",
        "    # Categorización de ingresos\n",
        "    def categorize_income(income):\n",
        "        if pd.isna(income):\n",
        "            return 'Unknown'\n",
        "        elif income < df_processed['Income'].quantile(0.25):\n",
        "            return 'Low'\n",
        "        elif income < df_processed['Income'].quantile(0.75):\n",
        "            return 'Medium'\n",
        "        else:\n",
        "            return 'High'\n",
        "\n",
        "    df_processed['Income_Category'] = df_processed['Income'].apply(categorize_income)\n",
        "\n",
        "    # Características de productos\n",
        "    product_columns = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "    df_processed['Total_Product_Spending'] = df_processed[product_columns].sum(axis=1)\n",
        "    df_processed['Spending_Diversity'] = (df_processed[product_columns] > 0).sum(axis=1)\n",
        "\n",
        "    # Selección de características\n",
        "    features = [\n",
        "        'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
        "        'NumDealsPurchases', 'NumWebPurchases',\n",
        "        'NumCatalogPurchases', 'NumStorePurchases',\n",
        "        'NumWebVisitsMonth', 'Education', 'Marital_Status',\n",
        "        'Income_per_Family_Member', 'Total_Purchases',\n",
        "        'Customer_Age', 'Days_Since_First_Purchase',\n",
        "        'Income_Category', 'Total_Product_Spending',\n",
        "        'Spending_Diversity'\n",
        "    ]\n",
        "\n",
        "    # Eliminar filas con valores NaN en características clave\n",
        "    df_processed_cleaned = df_processed.dropna(subset=features + ['MntWines'])\n",
        "\n",
        "    X = df_processed_cleaned[features]\n",
        "    y = df_processed_cleaned['MntWines']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def compare_models(X, y):\n",
        "    # Preparación de datos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Definición de modelos a comparar - AÑADIDOS SVR y KNeighborsRegressor\n",
        "    models = {\n",
        "        'Random Forest': RandomForestRegressor(random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
        "        'HistGradient Boosting': HistGradientBoostingRegressor(random_state=42),\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Support Vector Machine': SVR(kernel='rbf'),  # Añadido SVM\n",
        "        'K-Nearest Neighbors': KNeighborsRegressor()  # Añadido KNN\n",
        "    }\n",
        "\n",
        "    # Resultados de los modelos\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Preprocesamiento específico para cada modelo\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='median')),\n",
        "                    ('scaler', StandardScaler())\n",
        "                ]), X.select_dtypes(include=['int64', 'float64']).columns),\n",
        "                ('cat', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "                ]), X.select_dtypes(include=['object']).columns)\n",
        "            ])\n",
        "\n",
        "        # Pipeline para cada modelo\n",
        "        if name == 'Support Vector Machine':\n",
        "            # Para SVM, usamos un hiperplano con kernel RBF y escalado estándar\n",
        "            pipeline = Pipeline([\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "        elif name == 'K-Nearest Neighbors':\n",
        "            # Para KNN, necesitamos asegurar escalado\n",
        "            pipeline = Pipeline([\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "        else:\n",
        "            pipeline = Pipeline([\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('regressor', model)\n",
        "            ])\n",
        "\n",
        "        # Entrenamiento y evaluación\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        results[name] = {\n",
        "            'MSE': mean_squared_error(y_test, y_pred),\n",
        "            'MAE': mean_absolute_error(y_test, y_pred),\n",
        "            'R2': r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "    # Visualización de resultados\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    metrics = ['MSE', 'MAE', 'R2']\n",
        "\n",
        "    # Preparar datos para gráfico\n",
        "    model_names = list(results.keys())\n",
        "    metric_values = {metric: [results[model][metric] for model in model_names] for metric in metrics}\n",
        "\n",
        "    # Crear subplots para cada métrica\n",
        "    for i, metric in enumerate(metrics, 1):\n",
        "        plt.subplot(1, 3, i)\n",
        "        plt.bar(model_names, metric_values[metric])\n",
        "        plt.title(f'{metric} por Modelo')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Ejecución principal\n",
        "if __name__ == '__main__':\n",
        "    # Carga de datos\n",
        "    path = \"https://raw.githubusercontent.com/amankharwal/Website-data/master/marketing_campaign.csv\"\n",
        "    data = pd.read_csv(path, sep=';')\n",
        "\n",
        "    # A. Ingeniería de características\n",
        "    X, y = advanced_feature_engineering(data)\n",
        "\n",
        "    # C. Comparación de modelos\n",
        "    model_comparison_results = compare_models(X, y)\n",
        "\n",
        "    # Impresión de resultados de comparación\n",
        "    for model, metrics in model_comparison_results.items():\n",
        "        print(f\"\\nResultados para {model}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "id": "RTcbUVo3eOEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}